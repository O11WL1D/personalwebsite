---
title: "Lab for GEOG 3023: Statistics for Geography"
subtitle: "Week 7: Confidence Intervals and Hypothesis Testing"
author: FirstName LastName
output: 
  html_document:
    css: "lab.css"
---


<div class="instructions">

Complete all **Questions**, and submit the finished Rmd and HTML file onto Canvas. Don't forget to change the name field in the beginning to your first and last name. 

</div>

# Part 1: Confidence Intervals

## Introduction

If you have access to data on an entire population, say the size of every 
house in Ames, Iowa, it's straight forward to answer questions like, "How big 
is the typical house in Ames?" and "How much variation is there in sizes of 
houses?". If you have access to only a sample of the population, as is often 
the case, the task becomes more complicated. What is your best guess for the 
typical size if you only know the sizes of several dozen houses? This sort of 
situation requires that you use your sample to make inference on what your 
population looks like.

### Setting a seed

We will take some random samples and calculate confidence based
on these samples in this lab, which means you should set a seed at the top of your lab. 
Setting a seed will cause R to sample the same sample each time you knit your document.
This will make sure your results don't change each time you knit, and it will also 
ensure reproducibility of your work (by setting the same seed it will be possible to 
reproduce your results). You can set a seed like this:
```{r set-seed}
set.seed(9102015)               # do not change the seed for this lab


```
The number above is completely arbitrary. If you need inspiration, you can use your
ID, birthday, or just a random string of numbers. The important thing is that you
use each seed only once. You only need to do this once in your R Markdown document,
but make sure it comes before sampling.












### Load packages

In this part of the lab we will explore the data using the `dplyr` package and visualize it 
using the `ggplot2` package for data visualization. The data can be found in the enclosed csv file.

Let's load the packages.

```{r load-packages, message=FALSE}
library(dplyr)
library(tidyr)
library(infer)
library(ggplot2)
```









### The data

We consider real estate data from the city of Ames, Iowa. This is the same 
dataset used in the previous lab. The details of 
every real estate transaction in Ames is recorded by the City Assessor's 
office. Our particular focus for this lab will be all residential home sales 
in Ames between 2006 and 2010.  This collection represents our population of 
interest. In this lab we would like to learn about these home sales by taking 
smaller samples from the full population. Let's load the data.

```{r load-data}
ames<-read.csv('./ames.csv')
```






In this lab we'll start with a simple random sample of size 60 from the 
population. Note that the data set has information on many housing variables, but for the first 
portion of the lab we'll focus on the size of the house, represented by the 
variable `area`.

```{r sample}
n <- 60
samp <- sample_n(ames, n)
```







<div class="question">
**Q1 (3 pts):** Describe the distribution of homes in your sample. What would you 
say is the "typical" size within your sample? Also state precisely what you 
interpreted "typical" to mean. *When making a histogram, use `breaks=20`.* 

**Your answer:**

within the sample a typical value or the median is 1443.5

```{r describe-sample}
# type your code here:

samp

hist(samp$area,breaks=20)

samp %>%
summarize(median=median(area), mean=mean(area))

```
</div>















<div class="question">
**Q2 (2 pts):** True or False: My distribution should be similar to others' distributions who also collect random samples from this population, but it is likely not exactly the same since it's a random sample.

* True. 
* False. 


**Your answer:**

it should be somewhat similar, since as the clt indicates that samples from a larger dataset are a decent 
indication of the dataset's attributes. To get results that are closer to the dataset one could increase the number 
of datapoints sampled. 

</div>











## Confidence intervals

Return for a moment to the question that first motivated this lab: based on 
this sample, what can we infer about the population? Based only on this single 
sample, the best estimate of the average living area of houses sold in Ames 
would be the sample mean, usually denoted as $\bar{x}$ (here we're calling it 
`x_bar`). That serves as a good **point estimate** but it would be useful 
to also communicate how uncertain we are of that estimate. This uncertainty
can be quantified using a **confidence interval**.


A confidence interval for a population mean is of the following form
\[ \bar{x} + t^\star \frac{s}{\sqrt{n}} \]

You should by now be comfortable with calculating the mean and standard deviation of 
a sample in R. And we know that the sample size is 60. So the only remaining building
block is finding the appropriate critical value for a given confidence level. Since we don't know
exactly the population standard deviation, we can estimate it with the sample standard deviation. As mentioned
in the lecture, we will get the critical values using Student's t-distribution. We can
use the `qt` function for this task and since the sample size is 60, the degrees of freedom for t-distribution 
will be 60-1=59. *Remember that confidence levels and percentiles are not equivalent.* For example, a 95% confidence
level refers to the middle 95% of the distribution, and the critical value associated with this area will
correspond to the 97.5th percentile.

We can find the critical value for a 95% confidence interval using
```{r z_star_95}
t_star_95 <- qt(0.975, 59)
t_star_95
```

Let's finally calculate the confidence interval:
```{r ci}
samp %>%
  summarise(lower = mean(area) - t_star_95 * (sd(area) / sqrt(n)),
            upper = mean(area) + t_star_95 * (sd(area) / sqrt(n)))
```

To recap: even though we don't know what the full population looks like, we're 95% 
confident that the true average size of houses in Ames lies between the values *lower* 
and *upper*. There are a few conditions that must be met for this interval to be valid.






<div class="question">
**Q3 (3 pts):**  For the confidence interval to be valid, the sample mean must be normally distributed and have standard error $s / \sqrt{n}$. Which of the following is not a condition needed for this to be true?

* The sample is random. 
* The sample size, 60, is less than 10% of all houses. 
* The sample distribution must be nearly normal. 

**Your answer:**

c1: required, without the sample being random bias is introduced into the data.

c2: required, this ensures that the data is approxamately independent. 

c3: not required, the clt states that regardless of the distribution of the data, 
as more and more samples are collected the true average and sd form a normal distribution. 



</div>


## Confidence levels


<div class="question">
**Q4 (5 pts)** What does "95% confidence" mean?

* 95% of the time the true average area of houses in Ames, Iowa, will be in this interval. 
* 95% of random samples of size 60 will yield confidence intervals that contain the true average area of houses in Ames, Iowa. 
* 95% of the houses in Ames have an area in this interval. 
* We are 95% confident that the sample mean is in this interval. 

**Your answer:**

95% of random samples of size 60 will yield confidence intervals that contain the true average area of houses in Ames, Iowa. 


</div>












In this case we have the rare luxury of knowing the true population mean since we 
have data on the entire population. Let's calculate this value so that
we can determine if our confidence intervals actually capture it. We'll store it in a
data frame called `params` (short for population parameters), and name it `mu`.



```{r pop-mean}
params <- ames %>%
  summarise(mu = mean(area))
```



Using R, we're going to collect many samples to learn more about how sample 
means and confidence intervals vary from one sample to another.

Here is the rough outline:

-   Obtain a random sample.
-   Calculate the sample's mean and standard deviation, and use these to calculate
and store the lower and upper bounds of the confidence intervals.
-   Repeat these steps 50 times.


We can accomplish this using the `rep_sample_n` function. The following code takes 50 random samples of size `n` from the population (and remember we defined 
$n = 60$ earlier), and computes the upper and lower bounds of the confidence intervals based on these samples.

```{r calculate-50-cis}
ci <- ames %>%
        rep_sample_n(size = n, reps = 50, replace = TRUE) %>%
        summarise(lower = mean(area) - t_star_95 * (sd(area) / sqrt(n)),
                  upper = mean(area) + t_star_95 * (sd(area) / sqrt(n)))
```

Let's view the first five intervals:

```{r first-five-intervals}
ci %>%
  slice(1:5)
```

Next we'll create a plot similar to the right-hand side of the following figure we saw in class. 
![](./ci.jpg)













First step will be to create a new variable in 
the `ci` data frame that indicates whether the interval does or does not capture the 
true population mean. Note that capturing this value would mean the lower bound of the
confidence interval is below the value and upper bound of the confidence interval is
above the value. Remember that we create new variables using the `mutate` function.

```{r capture-mu}
ci <- ci %>%
  mutate(capture_mu = ifelse(lower < params$mu & upper > params$mu, "yes", "no"))
```

<!-- The `ifelse` function is new. It takes three arguments: first is a logical statement, -->
<!-- second is the value we want if the logical statement yields a true result, and the -->
<!-- third is the value we want if the logical statement yields a false result. -->

We now have all the information we need to create the plot, but we need to re-organize
our data a bit for easy plotting. Specifically, we need to organize the data in a new
data frame where each row represents one bound, as opposed to one interval. So this

~~~
     lower    upper capture_mu
1 1350.540 1544.360        yes
2 1333.441 1584.425        yes
3 1412.133 1663.801        yes
...
~~~

should instead look something like

~~~
  replicate   type     bound capture_mu
1         1  lower  1350.540        yes
2         2  lower  1333.441        yes
3         3  lower  1412.133        yes
4         1  upper  1544.360        yes
5         2  upper  1584.425        yes
6         3  upper  1663.801        yes
...
~~~

We can accomplish this using the following command provided in `tidyr` package:

```{r create-ci-data-for-plot}
ci_data <- gather(ci, type, bound, lower:upper)
```

And finally we can create the plot using the following:

```{r plot-ci}
# We briefly mentioned using ggplot to make plots in the class, but didn't ask you to do anything. Here is an example to 
# show the advantage of ggplot. It would take more code to only use R basic graphics (that we have used up until now, e.g.,
# plot()) to finish a similar plot.

ggplot(data = ci_data, aes(x = bound, y = replicate, 
                           group = replicate, color = capture_mu)) +
  geom_point(size = 2) +  # add points at the ends, size = 2
  geom_line() +           # connect with lines
  geom_vline(xintercept = params$mu, color = "darkgray") # draw vertical line
```











<div class="exercise">
**Q5 (4)** What proportion of your confidence intervals include the true population mean? 
Is this proportion exactly equal to the confidence level? If not, explain why.



**Your answer:**

The proportion is 98% This is not exactly equal to the confidence level, but it doesnt need to exactly equal. 
The 95th condifidence level guarentees a minimum of 95%, if its a little more thats alright. 



```{r find-proportion}
# type your code here



ci <- ci %>%
  mutate(capture_mu1 = ifelse(lower < params$mu & upper > params$mu, 1, 0))


length(ci$capture_mu1)

sum(
  ci$capture_mu1
  )


sum(
  ci$capture_mu1
  )/length(ci$capture_mu1)




```
</div>











<div class="question">
**Q6 (4 pts)** What is the appropriate critical value for a 99% confidence level for t-distribution with 59 degree of freedom?

* 0.01 
* 0.99  
* 1.96 
* 2.20 
* 2.66 



**Your answer:**

=2.66


```{r find-99-perc-crit-val}
# type your code here


qt(0.995, 59)   #for single tailed.  


```
</div>





























<div class="question">
**Q7 (7 pts)** Based on the previous code, please calculate 50 confidence intervals at the **99% confidence level**, and the proportion in which the mean lies within the interval.

**Your answer:**

```{r plot-99-perc-cis}
# type your code here

t_star_95 <- qt(0.995, 59)


ci <- ames %>%
        rep_sample_n(size = n, reps = 50, replace = TRUE) %>%
        summarise(lower = mean(area) - t_star_95 * (sd(area) / sqrt(n)),
                  upper = mean(area) + t_star_95 * (sd(area) / sqrt(n)))

ci <- ci %>%
  mutate(capture_mu = ifelse(lower < params$mu & upper > params$mu, "yes", "no"))


ci_data <- gather(ci, type, bound, lower:upper)


ggplot(data = ci_data, aes(x = bound, y = replicate, 
                           group = replicate, color = capture_mu)) +
  geom_point(size = 2) +  # add points at the ends, size = 2
  geom_line() +           # connect with lines
  geom_vline(xintercept = params$mu, color = "darkgray") # draw vertical line

```

</div>

# Part 2: Intro to Hypothesis Testing

In this part of the lab we will explore the data using the `dplyr` package and
visualize it using the `R` basic graphics for data visualization. The data
 ('nc.csv') is enclosed. 

### The data

In 2004, the state of North Carolina released a large data set containing 
information on births recorded in this state. This data set is useful to 
researchers studying the relationship between characteristics and practices of expectant 
mothers and their baby's birth outcomes. We will work with a random sample of 
observations from this data set.

Load the `nc` data set into our workspace.

```{r load-part2-data}
nc<-read.csv('./nc.csv')
```

We have observations on 13 different variables, some categorical and some 
numerical. The meaning of each variable is as follows.

variable         | description
---------------- | ---------------------------------------------
`mage`           | mother's age in years.
`fage`           | father's age in years.
`mature`         | maturity status of mother.
`weeks`          | length of pregnancy in weeks.
`premie`         | whether the birth was classified as premature (premie) or full-term.
`visits`         | number of hospital visits during pregnancy.
`marital`        | whether mother is `married` or `not married` at birth.
`gained`         | weight gained by mother during pregnancy in pounds.
`weight`         | weight of the baby at birth in pounds.
`lowbirthweight` | whether baby was classified as low birthweight (`low`) or not (`not low`).
`gender`         | gender of the baby, `female` or `male`.
`habit`          | status of the mother as a `nonsmoker` or a `smoker`.
`whitemom`       | whether mom is `white` or `not white`.





As a first step in the analysis, we should take a look at the variables in
the dataset. This can be done using the following commonly used commands:
```{r str}

# show the structure of the data frame
str(nc)

# display the first few lines of the data frame
head(nc)

# return the dimension of the data frame
dim(nc)

# return summaries of each variable
summary(nc)
```

As you review the variable summaries, keep your eyes peeled for any outliers -- does it seem like the max (or min) is really high (or really low) for any numeric variables? If you aren't sure or want to take a closer look at the data, make a plot(s).

## Exploratory data analysis

We will first start with analyzing the weight gained by mothers throughout the 
pregnancy: `gained` (the weight gained by mothers during pregnancy). Note that there are missing values (NA's) in the dataset. 

```{r summary}
summary(nc$gained)
```

Consider the possible relationship between a mother's smoking habit and the weight of her baby. Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions.

```{r}
boxplot(weight ~ habit, data=nc)

```





<div class="question">
**Q8 (3 pts):** Which of the following is false about the relationship between habit and weight? 

* Median birth weight of babies born to non-smoker mothers is slightly higher than that of babies born to smoker mothers. 
* Range of birth weights of babies born to non-smoker mothers is smaller than that of babies born to smoker mothers. 
* The IQRs of the distributions are roughly equal. 

**Your answer:**

1.TRUE, the median is slightly higher on the graph as compared to the smoker mother dataset.
2. FALSE, the range or the difference between the last values within q1 and q3 is larger than that of the smoker mother dataset. 
3. TRUE, the IQRS of both distributions are roughtly equal. 


</div>

The box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the following to 
first group the data by the `habit` variable, and then calculate the mean
`weight` in these groups using the `mean` function.

```{r by-means}
nc %>%
  group_by(habit) %>%
  summarise(mean_weight = mean(weight))
```

There is an observed difference, but *is this difference statistically significant*? To answer this question, we will conduct a hypothesis test.























## Hypothesis test of population mean

<div class="question">
**Q9 (4 pts):**  What are the hypotheses for testing if the average weights of babies born to smoking and non-smoking mothers are different?

* $H_0: \mu_{smoking} = \mu_{non-smoking}$; $H_A: \mu_{smoking} > \mu_{non-smoking}$ 
* $H_0: \mu_{smoking} = \mu_{non-smoking}$; $H_A: \mu_{smoking} \ne \mu_{non-smoking}$ 
* $H_0: \bar{x}_{smoking} = \bar{x}_{non-smoking}$; $H_A: \bar{x}_{smoking} > \bar{x}_{non-smoking}$ 
* $H_0: \bar{x}_{smoking} = \bar{x}_{non-smoking}$; $H_A: \bar{x}_{smoking} > \bar{x}_{non-smoking}$ 
* $H_0: \mu_{smoking} \ne \mu_{non-smoking}$;  $H_A: \mu_{smoking} = \mu_{non-smoking}$ 

**Your answer:**

The set of hypothesis are number 2:
* $H_0: \mu_{smoking} = \mu_{non-smoking}$; $H_A: \mu_{smoking} \ne \mu_{non-smoking}$ 

</div>

We first need to know the weights for the `smoker` and `nonsmoker`:

```{r}
smoker <- nc %>%
    filter(nc$habit=='smoker')

nonsmoker <- nc %>%
    filter(nc$habit=='nonsmoker')

```

The hypothesis test can then be easily done with the `R` function
`t.test()`. Note we can specify the level of significance through
`conf.level` and the associated confidence level will also be output.

```{r}
t.test(smoker$weight, nonsmoker$weight)

## 0.95 is the default, so this would return the same answer:
   # t.test(smoker$weight, nonsmoker$weight, conf.level=0.95) 
```

Or more conveniently, we can simply run `t.test()` like the following
without separating the smoker and non-smoker. Note: order matters! You need to know which one is the *response variable* (lefthand side) and which one is the
*explanatory variable* (righthand side). 


```{r}
t.test(weight ~ habit, data=nc)
```




















<div class="question">
**Q10 (5 points):** Based on the output of `t.test()`, what is the conclusion of this hypothesis test?

**Your answer:**
The p value is 0.01945 and is less than 5% so we reject the null hypothesis. 


</div>

The previous code tested whether the weights of smoker and nonsmoker are
*different* from each other. It was a "two-sided test", since it didn't tell us
which one was larger or smaller, just whether they were different. We can change the null hypothesis to be that the birthweight from a smoking mother is *greater than or equal to* the birthweight from a non-smoking mother.
(Remember we mentioned in lecture that the null hypothesis tends to be
something we'd like to reject.) This becomes a single-sided test. In other words:

- $H_0: \mu_{smoking} >= \mu_{non-smoking}$; $H_A: \mu_{smoking} < \mu_{non-smoking}$ 
- Equivalently: $H_0: \mu_{smoking} - \mu_{non-smoking} >= 0 $; $H_A: \mu_{smoking} - \mu_{non-smoking} < 0$

To do this test, we can simply use:

```{r}
t.test(smoker$weight, nonsmoker$weight, alternative='less')
```

Comparing this output with the previous `t.test()`, what do you notice in
terms of the *p-value*?










<div class="question">
 **Q11 (10 pts):** In the dataset, we also know the `gender` of each birth. We'd like to know if there are significant differences between `male` and `female` baby birthweights. Please
formulate your hypothesis, conduct the hypothesis test, and describe your
decision (reject or fail to reject the hypothesis)

**Your answer:**

The hypothesis I am testing is: 
$H_0: \mu_{male_weight} = \mu_{female_weight}$; $H_A: \mu_{male_weight} \ne \mu_{female_weigt}$ 

The p score from the test is significantly lower than 5%, so we reject the null hypothesis. 

```{r}
# Please type your code here:
male <- nc %>%
    filter(nc$gender=='male')

female <- nc %>%
    filter(nc$gender=='female')


t.test(male$weight, female$weight)



```

</div>








